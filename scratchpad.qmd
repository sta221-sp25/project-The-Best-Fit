---
title: "Project Proposal"
author: "The BEST Fit - Olivia Encarcion, Leo Yang, Philip Lin, Allison Yang"
format: pdf
execute: 
  warning: false
editor: visual
---

```{r}
newsdf$is_viral <- ifelse(newsdf$shares >= 1400, 1, 0)


logistic_model <- glm(is_viral ~ kw_avg_avg  + n_tokens_content + data_channel +
                  is_weekend + global_subjectivity +
                  title_sentiment_polarity, 
                family = binomial(link = "logit"),
                data = newsdf)

```

```{r}
pred_prob <- predict.glm(logistic_model, type = "response")

model_aug <- augment(logistic_model)

model_aug <- model_aug |>
  mutate(is_viral = as.factor(is_viral))

model_aug <- model_aug |>
  bind_cols(pred_prob = pred_prob)
# calculate sensitivity and specificity at each threshold
roc_curve_data <- model_aug |>
roc_curve(is_viral, pred_prob,
event_level = "second")
# plot roc curve
autoplot(roc_curve_data)
```

```{r}

target_sensitivity <- 0.65

closest_point <- roc_curve_data |>
  mutate(diff = abs(sensitivity - target_sensitivity)) |>
  arrange(diff) |> 
  slice(1)

closest_point$.threshold
```

```{r}
log_odds <- predict(logistic_model, newsdf)
newsdf <- newsdf |>
  bind_cols(log_odds = log_odds)
newsdf <- newsdf |>
  mutate(
    predict_prob = exp(log_odds) / (1 + exp(log_odds))
  )

newsdf <- newsdf |>
  mutate(
    estimateVirality = case_when(
      predict_prob < 0.4916522 ~ 0,
      predict_prob > 0.4916522 ~ 1,
      TRUE ~ NA_real_  
    )
  )

newsdf <- newsdf |> 
  mutate(
         estimateVirality = as.factor(estimateVirality),
         is_viral = as.factor(is_viral)
         )

model_conf <- newsdf |>
  conf_mat(is_viral,estimateVirality)

autoplot(model_conf, type="heatmap")
```

```{r}

newsdf$is_viral <- as.factor(newsdf$is_viral)

ggplot(data = newsdf, aes(x=data_channel, fill=is_viral )) + 
    geom_bar(position="fill")


```

```{r}
newsdf <- newsdf|>
  mutate(
    is_viral = factor(is_viral, 
                       levels = c(0,1), 
                       labels = c("Not Viral", "Viral"))
  )

ggplot(data = newsdf, aes(x=day_published, fill=is_viral )) + 
    geom_bar(position="fill")

```

`{# TODO - Subjectiity has varying effects based on data channel, show that}`

```{r}
#| label: interaction-subjectivity-data_channel 

ggplot(newsdf, aes(fill=is_viral, y=global_subjectivity)) + 
  geom_boxplot(position = position_dodge()) + 
  facet_wrap(~ data_channel) + 
  coord_flip(ylim = c(0, 0.6)) + 
  labs(
    y = "Global Subjectivity", 
    fill = "Virality"
  )

```

```{r}
#| label: interaction-length-virality 
ggplot(newsdf, aes(fill=is_viral, y=log(n_tokens_content))) + 
  geom_boxplot(position = position_dodge(width = 0.8)) + 
  facet_wrap(~ data_channel) + 
  coord_cartesian(ylim = c(-0.1, 0.1)) + 
  coord_flip(ylim = c(4, 8)) +
  labs(
    y = "Article Body Length (log transformed)", 
    fill = "Virality"
  )
```

```{r}
#| echo: false
#| message: false
#| warning: false

nullMod <- glm(is_viral ~ log(kw_avg_avg+0.0001) + log(n_tokens_content+0.0001) + data_channel +
                 day_published + global_subjectivity +
                 title_sentiment_polarity, 
               family = binomial(link = "logit"),
               data = newsdf)

interactsMod <- glm(is_viral ~ log(kw_avg_avg+0.0001) + log(n_tokens_content+0.001) + data_channel +
                     day_published + global_subjectivity +
                     title_sentiment_polarity + log(n_tokens_content+ 0.001) * data_channel, 
                   family = binomial(link = "logit"),
                   data = newsdf)

# Extract log-likelihoods
L_0 <- glance(nullMod)$logLik
L_a <- glance(interactsMod)$logLik

# Calculate test statistic
G <- -2 * (L_0 - L_a)

# Calculate p-value
p_value <- pchisq(G, df = 5, lower.tail = FALSE)

# Create table for drop in deviance test
deviance_table <- tibble(
  Model = c("Null Model", "Interaction Model"),
  `Log-Likelihood` = c(L_0, L_a),
  `Deviance Statistic (G)` = c(NA, G),
  df = c(NA, 5),
  `p-value` = c(NA, p_value)
)

# Display table using knitr::kable
knitr::kable(deviance_table, 
             caption = "Drop in Deviance Test Results",
             digits = c(0, 3, 3, 0, 4))

```

$$ 
\begin{aligned}
H_0: \text{logit}(P(\text{is_viral} = 1)) &= \beta_0 \\
&+ \beta_1 \times \log(\text{kw_avg_avg} + 0.0001) \\
&+ \beta_2 \times \log(\text{n_tokens_content} + 0.0001) \\
&+ \beta_3 \times \text{data_channel} \\
&+ \beta_4 \times \text{day_published} \\
&+ \beta_5 \times \text{global_subjectivity} \\
&+ \beta_6 \times \text{title_sentiment_polarity}
\end{aligned}
$$

$$ 
\begin{aligned}
H_a:\text{logit}(P(\text{is_viral} = 1)) &= \beta_0 \\
&+ \beta_1 \times \log(\text{kw_avg_avg} + 0.0001) \\
&+ \beta_2 \times \log(\text{n_tokens_content} + 0.0001) \\
&+ \beta_3 \times \text{data_channel} \\
&+ \beta_4 \times \text{day_published} \\
&+ \beta_5 \times \text{global_subjectivity} \\
&+ \beta_6 \times \text{title_sentiment_polarity} \\
&+ \beta_7 \times (\text{n_tokens_content} \times \text{data_channel})
\end{aligned}
$$

### Methodology

Since initial EDA revealed a heavy right skew in the distribution of article shares, as well as a poential non-linear relationship, we elected to use a logistic regression model with a transformed binary response variable.

Based on our initial EDA and empirical logit visualization, we selected data channel, day published, article subjectivity, title sentiment polarity, log transformed 'avg keyword popularity', and log transformed article content length to fit an initial logistic model.

For the response variable, we constructed "is_viral" by transforming 'share' count into a binary response variable, with 1 for articles more popular than 1400 shares and 0 for those with less. We selected this threshold of 1400 shares based on prior literature\[CITE HERE\] and the recommendation of the data set curator.

$$ 
\begin{aligned}
\text{logit}(P(\text{is_viral} = 1)) &= \beta_0 \\
&+ \beta_1 \times \log(\text{kw_avg_avg} + 0.0001) \\
&+ \beta_2 \times \log(\text{n_tokens_content} + 0.0001) \\
&+ \beta_3 \times \text{data_channel} \\
&+ \beta_4 \times \text{day_published} \\
&+ \beta_5 \times \text{global_subjectivity} \\
&+ \beta_6 \times \text{title_sentiment_polarity}
\end{aligned}
$$

```{r}
#| label: log-model 

newsdf$is_viral <- ifelse(newsdf$shares >= 1400, 1, 0)


logistic_model <- glm(is_viral ~ log(kw_avg_avg + 0.0001)  + log(n_tokens_content + 0.0001) + data_channel +
                  day_published + global_subjectivity +
                  title_sentiment_polarity, 
                family = binomial(link = "logit"),
                data = newsdf)

tidy(logistic_model) |>
  mutate(
    estimate = round(estimate, 4),
    std.error = round(std.error, 4),
    statistic = round(statistic, 4),
    p.value = round(p.value, 4)
  ) %>%
  kable(digits = 4, align = "lrrrr",
        col.names = c("Term", "Estimate", "Std.Error", "z-statistic", "p-value"))
```

Our initial fit gives all of the predictors significant p-values (p\<0.05) and most predictors relatively high magnitude z-statistics, indicating that all variables in the model have statistically significant relationships with the likelihood of content going viral.

Next, we considered the addition

As for predictors, we continued using statistically significant predictors data_channel,day_published, etc.

```{r}
tidy(logistic_model) |>
kable(digits= 4)
```

```{r}
#| label: plot-roc-curve 
pred_prob <- predict.glm(logistic_model, type = "response")

model_aug <- augment(logistic_model)

model_aug <- model_aug |>
  mutate(is_viral = as.factor(is_viral))

model_aug <- model_aug |>
  bind_cols(pred_prob = pred_prob)
# calculate sensitivity and specificity at each threshold
roc_curve_data <- model_aug |>
roc_curve(is_viral, pred_prob,
event_level = "second")
# plot roc curve
autoplot(roc_curve_data)

```

```{r}
#| label: original-auc 

auc_original <- roc_auc(
  data = model_aug, 
  truth = is_viral, 
  pred_prob,
  event_level = "second"
)

auc_original
```

From the ROC curve, we estimated that the best threshold for our model would be when sensitivity was about 0.65. Thus, we found the closest point on the ROC curve to sensitivity = 0.65, which we found to be when threshold = 0.492. Using this calculation, we were then able to predict the virality categorization for each observation and generate our confusion matrix, as shown below.

```{r}
#| label: select-threshold

target_sensitivity <- 0.65

closest_point <- roc_curve_data |>
  mutate(diff = abs(sensitivity - target_sensitivity)) |>
  arrange(diff) |> 
  slice(1)

closest_point$.threshold

```

```{r}
#| label: confusion-matrix

log_odds <- predict(logistic_model, newsdf)
newsdf <- newsdf |>
  bind_cols(log_odds = log_odds)
newsdf <- newsdf |>
  mutate(
    predict_prob = exp(log_odds) / (1 + exp(log_odds))
  )

newsdf <- newsdf |>
  mutate(
    estimateVirality = case_when(
      predict_prob < 0.4916522 ~ 0,
      predict_prob > 0.4916522 ~ 1,
      TRUE ~ NA_real_  
    )
  )

newsdf <- newsdf |> 
  mutate(
         estimateVirality = as.factor(estimateVirality),
         is_viral = as.factor(is_viral)
         )

model_conf <- newsdf |>
  conf_mat(is_viral,estimateVirality)

autoplot(model_conf, type="heatmap")

```
