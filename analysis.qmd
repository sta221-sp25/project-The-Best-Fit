```{r}
library(pROC)

```

**Analysis + peer review**

**Draft report**

**Introduction and data**

Our project utilizes the University of California Irvine Machine Learning Repository’s  “Online News Popularity” data set. It includes share counts and descriptive characteristics for articles published by Mashable over two years (from 2013 to 2015). Mashable Inc. is a digital media website founded in 2005 and as of November 2015, it has over 6,000,000 Twitter followers and over 3,200,000 fans on Facebook. The data set in total, has 39644 observations, each representing an individual article. Our project motivation is that with the rise of the internet, we're interested in seeing how different factors influence or decide what goes "viral" on social media. For media companies specifically, this could aid in revealing patterns in what attracts readers to certain articles. Thus, our project aims to answer the **key research question**:

How do different article attributes (ex. Polarity, Positive/Negative Sentiments, Number of Images, etc.) relate to its virality on social media?

**Key Variables:** 

rate_positive_words -  rate of positive words among non-neutral tokens, which captures how emotionally charged the language is. 

Rate_negative_words - rate of negative words among non-neutral tokens, which captures how emotionally charged the language is. 

title_sentiment_polarity - A measure of how polarizing the title is

N_tokens_content - A measure of how long the article’s content is 

N_tokens_title -  A measure of how long the article title is

data_channel - a categorical variable denoting article topic merged from: Data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, and data_channel_is_world.

day_published- a categorical variable indicating publication day merged from indicators: Weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday,weekday_is_saturday, weekday_is_sunday 

**Key EDA**

Response Variable - our initial EDA of the response variable revealed that it had a heavily right skewed, unimodal distribution. Thus, we imposed a log transformation, which was more symmetric and normally distributed.

```{r}
#| label: initial-response 

ggplot(newsdf, aes(x = shares)) +
  geom_histogram(binwidth = 500, fill = "blue", color = "black", alpha = 0.7) +
  scale_x_continuous(limits = c(0, 50000)) +  # Limit for better visualization
  labs(title = "Distribution of Article Shares",
       x = "Number of Shares",
       y = "Count") +
  theme_minimal()
```

```{r}
#| label: log-transform-response 

ggplot(newsdf, aes(x = log(shares))) +  
  geom_histogram(binwidth = 0.2, fill = "purple", color = "black", alpha = 0.7) +
  labs(title = "Log-Transformed Distribution of Shares",
       x = "Log(Shares)",
       y = "Count") +
  theme_minimal()
```

Key Variables - The key predictor variables we found from our initial exploration were Data Channel and Day Published, with the bivariate EDA we performed with our response variable, log(shares), shown below.

```{r}
#| label: distribution-day-pub

news_summary <- newsdf |>
  group_by(day_published) |> 
  summarize(mean_shares = mean(shares)) 

head(news_summary)
news_summary|>
  ggplot(aes(x = day_published, y = mean_shares)) +
  geom_bar(stat = "identity", fill = "skyblue") + 
  labs(
    x = "Day Published", 
    y = "Mean Number of Article Shares",
    title = "Mean Number of Article Shares vs. Day Published"
  )
```

```{r}
#| label: data-channel-explore

news_summary_channel <- newsdf |>
  group_by(data_channel) |> 
  summarize(mean_shares = mean(shares)) 

head(news_summary_channel)
news_summary_channel |>
  drop_na(data_channel) |>
  ggplot(aes(x = data_channel, y = mean_shares)) +
  geom_bar(stat = "identity", fill = "skyblue") + 
  labs(
    x = "Data Channel", 
    y = "Mean Number of Article Shares",
    title = "Mean Number of Article Shares vs. Data Channel"
  )
```

#### Methodology

From our EDA, we found that the most significant predictor variables were data_channel and day_published, however, other predictors we initially viewed (such as n_tokens_title, etc.) were not significant. Thus, we chose to fit an initial MLR model using data_channel and day_published, alongside other predictors that we hadn't attempted before (such as kw_avg_avg, n_tokens_content, etc.).

This produced said results:

```{r}
#| label: MLR-initial 

mlr_model <- lm(log(shares) ~ kw_avg_avg + n_tokens_content + 
              data_channel + day_published + global_subjectivity +
              title_sentiment_polarity, 
              data = newsdf)
tidy(mlr_model) |>
  kable(digits = 3)
```

We found that all our predictors were statistically significant (p-value \< 0.05), with the exception of day_publishedFriday, and thus kept them in this model.

```{r}
#| label: MLR-res

summary_result <- summary(mlr_model)

rmse_val <- sqrt(mean(summary_result$residuals^2))

results_table <- data.frame(
  Metric = c("R^2", "Adjusted R-squared", "RMSE"),
  Value = c(
    round(summary_result$r.squared, 4),
    round(summary_result$adj.r.squared, 4),
    round(rmse_val, 4)
  )
)

results_table
```

```{r}
#| label: residuals-plot

plot(mlr_model, which = c(1))
```

Our MLR had an $RMSE$ of 0.8303 and $R^2$ value of 0.0903 . Considering that our response variable was log(shares), this suggests that this MLR model is poorly fit to our data, as it can only explain about 9.03% of the variability that we can see from our response variable, log(shares), and moreover, has a very high RMSE value. This is reaffirmed by the residuals plot, which reveals that the residuals are not randomly distributed, meaning that linear regression might not be the ideal model as our data does not satisfy the linear regression criteria. 

Thus, for our final model, we pivoted to use a logistic regression model to classify an article as popular or otherwise, with a threshold for popularity of "1400 shares" based on prior literature. We transformed the shares column into a binary response variable, with 1 for articles more popular than 1400 shares and 0 for those with less.

```{r}
#| label: log-model 

news_data$is_viral <- ifelse(news_data$shares >= 1400, 1, 0)


logistic_model <- glm(is_viral ~ kw_avg_avg + n_tokens_content + 
                  data_channel_is_entertainment + data_channel_is_socmed +
                  data_channel_is_tech + data_channel_is_bus +
                  weekday_is_tuesday + global_subjectivity +
                  title_sentiment_polarity, 
                family = binomial(link = "logit"),
                data = news_data)
summary_result <- summary(logistic_model)

news_data$predicted_prob <- predict(logit_model, type = "response")
news_data$predicted_class <- ifelse(news_data$predicted_prob >= 0.5, 1, 0)

confusion_matrix <- table(news_data$is_viral, news_data$predicted_class)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2,2] / sum(confusion_matrix[,2])


roc_obj <- roc(news_data$is_viral, news_data$predicted_prob)
auc_value <- auc(roc_obj)


results_table <- data.frame(
  Metric = c("Accuracy", "Precision","AUC"),
  Value = c(
    round(accuracy, 4),
    round(precision, 4),
    round(auc_value, 4)
  )
)


kable(results_table, format = "html", caption = "Logistic Regression Performance Metrics") %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = FALSE)


```

#### Results

In this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.

This section also includes initial interpretations and conclusions drawn from the model.
