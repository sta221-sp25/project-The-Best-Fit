---
title: "Analysis Written Report"
author: "The BEST Fit - Philip, Olivia, Leo, Allison"
date: "4/10/2025"
format: pdf
execute: 
  warning: false
  message: false
  echo: false
editor: visual
---

```{r}
#| label: load-pkg-data

library(pROC)
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(knitr)
install.packages("gridExtra")
if (!requireNamespace("car", quietly = TRUE)) {
  install.packages("car")
}
library(car)

newsdf <- read_csv("data/OnlineNewsPopularity.csv")
```

## **Analysis + Peer Review**

[**Draft report**]{.underline}

[**Introduction**]{.underline}

The ways in which people interact with media and discover news have dramatically shifted in recent years, with social media often displacing traditional news outlets. The decentralized nature of social media means the reach of each article is largely dependent on its individual merits, rather than the popularity of the publication it belongs to.

Thus a question arises: What article attributes are associated with social media virality?

In this report we will investigate the effects of different article features on social media success using the University of California Irvine Machine Learning Repository’s “Online News Popularity” data set. It includes share counts and descriptive characteristics for articles published by Mashable, a digital media website, over two years (from 2013 to 2015). The data has 39,644 entries in total, with each repsenting an individual article and its associated textual and metadata features.

**Key Variables:** 

**rate_positive_words** - Rate of positive words among non-neutral tokens in the article content. Values range from 0.0 to 1.0, with a mean of 0.6822 and standard deviation of 0.1902. This metric captures the positive emotional tone of the article.

**Rate_negative_words** - Rate of negative words among non-neutral tokens in the article content. Values range from 0.0 to 1.0, with a mean of 0.2879 and standard deviation of 0.1562. This metric captures the negative emotional tone of the article.

**title_sentiment_polarity** - Measure of the title's sentiment polarity (positivity/negativity). Values range from -1.0 (extremely negative) to 1.0 (extremely positive), with a mean of 0.0714 and standard deviation of 0.2654. This indicates how emotionally charged article titles are.

**n_tokens_content** - Number of words in the article content. Values range from 0 to 8,474 words, with a mean of 546.51 and standard deviation of 471.10. This quantifies the overall length of the article.

**n_tokens_title** - Number of words in the article title. Values range from 2 to 23 words, with a mean of 10.40 and standard deviation of 2.11. This measures length of headlines.

**data_channel** - Categorical variable denoting article topic, merged from indicators: data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, and data_channel_is_world. This classifies content by subject area.

**day_published** - Categorical variable indicating publication day, merged from indicators: weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday, weekday_is_sunday. Additionally includes is_weekend (mean 0.1309) to distinguish weekday from weekend publications.

**kw_avg_avg** - Average shares of average keywords in the article. Values range from 0.0 to 43,567.66, with a mean of 3,135.86 and standard deviation of 1,318.13. This measures the expected popularity of the article's keyword selection.

**global_subjectivity** - Measures the overall subjectivity of the article text. Values range from 0.0 (completely objective) to 1.0 (completely subjective), with a mean of 0.4434 and standard deviation of 0.1167. This quantifies how opinion-based versus fact-based the content is.

### **Univariate Exploratory Data Analysis**

To understand our response and predictor variables more deeply, we first looked at their individual distributions. We found that while some variables are relatively approximately symmetric, others are heavily skewed and required log transformations to better meet modeling assumptions.

```{r}
install.packages("gridExtra")
p1 <- ggplot(newsdf, aes(x = title_sentiment_polarity)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
   labs(title = "Dist. of Title Sentiment",
       x = "Title Sentiment Score",
       y = "Count of Articles") +
  theme_minimal()

p2 <- ggplot(newsdf, aes(x = global_subjectivity)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
   labs(title = "Dist. of Article Subjectivity",
       x = "Subjectivity Score",
       y = "Count of Articles") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```

The title_sentiment_polarity variable quantifies the emotional change of article titles. The distribtuion suggests that many titles are emotionally neutral. The global_subjectivity variable is rougly symmetric with its distribution suggesting that most articles contained a balanced mix of factual and opinion-based language. Both global_subjectivity and title_sentiment_popularity display relatively balanced distributions that do not require transformation.

```{r}
ggplot(newsdf, aes(x = kw_avg_avg)) +
  geom_histogram(binwidth = 500, fill = "blue", color = "black", alpha = 0.7) +
   labs(title = "Dist. of Keyword Popularity",
       subtitle = "Average shares of average keywords",
       x = "Avg. Shares of Avg. Keywords",
       y = "Count of Articles") +
  theme_minimal()
```

```{r}
p5 <- ggplot(newsdf, aes(x = n_tokens_content)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
   labs(title = "Dist. of Article Length",
       x = "Word Count",
       y = "Count of Articles") +
  theme_minimal()

p6 <- ggplot(newsdf, aes(x = log(n_tokens_content))) +  
  geom_histogram(fill = "purple", color = "black", alpha = 0.7) +
  labs(title = "Dist. of Article Length (Log-Trans.)",
       x = "Word Count (Log-trans.)",
       y = "Count of Articles")+
  theme_minimal()

grid.arrange(p5, p6, ncol = 2)
```

response

```{r}
p7 <- ggplot(newsdf, aes(x = shares)) +
  geom_histogram(binwidth = 500, fill = "blue", color = "black", alpha = 0.7) +
  scale_x_continuous(limits = c(0, 50000)) +  # Limit for better visualization
   labs(title = "Dist. Article Popularity",
       x = "Number of Shares",
       y = "Count of Articles") +
  theme_minimal()

p8 <- ggplot(newsdf, aes(x = log(shares))) +  
  geom_histogram(binwidth = 0.2, fill = "purple", color = "black", alpha = 0.7) +
  labs(title = "Dist. Article Popularity (Log-Trans.)",
       x = "Shares (Log-trans.)",
       y = "Count of Articles")+
  theme_minimal()

grid.arrange(p7, p8, ncol = 2)
```

Response Variable - our initial EDA of the response variable revealed that it had a heavily right skewed, unimodal distribution. Thus, we imposed a log transformation, which was more symmetric and normally distributed.

Both `n_tokens_content` and `kw_avg_avg` displayed heavily right-skewed distributions that warranted log transformations.To correct for this skewness and reduce the influence of extreme values, we log-transformed both variables. Post-transformation, the distributions became more symmetric and centered, better aligning with modeling assumptions.

The original distribution of the `shares` variable was extremely right-skewed, with the majority of articles receiving low engagement and a small number going viral. This made it difficult to model using linear approaches due to non-normal residuals and unequal variance.

We applied a log transformation to address this skewness. The transformed distribution is notably more symmetric and bell-shaped, making it more appropriate for regression analysis and enabling clearer interpretation of the effects of predictor variables on article popularity.

### **Data Cleaning**

[Data Cleaning]{.underline}

This data cleaning step restructures the dataset by converting multiple binary indicator columns into more interpretable categorical variables.

```{r}
newsdf$day_published <- NA  # Create a new empty column

newsdf$day_published <- case_when(
  newsdf$weekday_is_monday == 1 ~ "Monday",
  newsdf$weekday_is_tuesday == 1 ~ "Tuesday",
  newsdf$weekday_is_wednesday == 1 ~ "Wednesday",
  newsdf$weekday_is_thursday == 1 ~ "Thursday",
  newsdf$weekday_is_friday == 1 ~ "Friday",
  newsdf$weekday_is_saturday == 1 ~ "Saturday",
  newsdf$weekday_is_sunday == 1 ~ "Sunday",
)

newsdf$day_published <- factor(
  newsdf$day_published,
  levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
)


newsdf$data_channel <- NA

newsdf$data_channel <- case_when(
  newsdf$data_channel_is_entertainment == 1 ~ "Entertainment",
  newsdf$data_channel_is_bus == 1 ~ "Business",
  newsdf$data_channel_is_socmed == 1 ~ "Social Media",
  newsdf$data_channel_is_tech == 1 ~ "Technology",
  newsdf$data_channel_is_world == 1 ~ "World",
)

newsdf$data_channel <- factor(newsdf$data_channel)


tab <- newsdf %>%
  select(url, day_published, data_channel) %>%
  head(5)
kable(tab, caption = "Transformed Data")
```

### **Bivariate Exploratory Data Analysis**

```{r}
newsdf$is_viral <- ifelse(newsdf$shares >= 1400, 1, 0)

newsdf |>
  group_by(data_channel, is_viral) |>
  summarise(n = n()) |>
  mutate(prop = n / sum(n)) |> 
  ggplot(aes(x = data_channel, y = prop, fill = factor(is_viral))) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Proportion of Viral Articles by Data Channel",
       x = "Data Channel", y = "Proportion",
       fill = "Is Viral") +
  coord_flip() +
  theme_minimal()

newsdf$day_published <- NA  # Create a new empty column

newsdf$day_published <- case_when(
  newsdf$weekday_is_monday == 1 ~ "Monday",
  newsdf$weekday_is_tuesday == 1 ~ "Tuesday",
  newsdf$weekday_is_wednesday == 1 ~ "Wednesday",
  newsdf$weekday_is_thursday == 1 ~ "Thursday",
  newsdf$weekday_is_friday == 1 ~ "Friday",
  newsdf$weekday_is_saturday == 1 ~ "Saturday",
  newsdf$weekday_is_sunday == 1 ~ "Sunday",
)

newsdf$day_published <- factor(
  newsdf$day_published,
  levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
)

newsdf |>
  group_by(day_published, is_viral) |>
  summarise(n = n(), .groups = "drop") |>
  group_by(day_published) |>
  mutate(prop = n / sum(n)) |>
  ggplot(aes(x = day_published, y = prop, fill = factor(is_viral))) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Proportion of Viral vs. Non-Viral Articles by Day Published",
       x = "Day Published", y = "Proportion",
       fill = "Is Viral") +
  coord_flip() +
  theme_minimal()

```

The first graph explores how virality varies across different content categories, as captured by the data_channel variable. Article published under the Social Media category have the highest proportion of viral outcomes, with many reaching viral status, This suggest that content tailored for or about social platforms may be particularly good for engagement. Articles that are categoized under Technology and Business also show strong performance, with over half of the articles in each category going viral, On the other hand, articles in the Entertainment and World categories are less likely to go viral, falling below the 50% mark. This graph underscores how topic area influences content reach potentially because of the differences in audience behavior or platform algorithms.

The second graph examines the relationship between the day an article is published and its likelihood of going viral. Articles published on weekends are substantially more likely to be viral compared to those published during the week. Saturday stands out with the highest porportion of viral content, followed closely by Sunday. In contrast, weekday article tend to have lower virality rates, with viral and non-viral occurring in nearly equal proportions. These findings suggest that timing plays a role in determining an article's reach, likely reflecting differences in user engagement patterns across the week.

```{r}
logistic_model <- glm(is_viral ~ log(kw_avg_avg + 0.0001)  + log(n_tokens_content + 0.0001) + data_channel +
                  day_published + global_subjectivity +
                  title_sentiment_polarity, 
                family = binomial(link = "logit"),
                data = newsdf)

log_odds <- predict(logistic_model, newsdf)
newsdf <- newsdf |>
  bind_cols(log_odds = log_odds)
newsdf <- newsdf |>
  mutate(
    predict_prob = exp(log_odds) / (1 + exp(log_odds))
  )

p11 <- ggplot(data = newsdf, aes(x = kw_avg_avg, y = log_odds)) +
  geom_point(size = 3, color = "blue") +  
  geom_smooth(method = "lm", se = FALSE, color = "red") +  
  labs(
    title = "Empirical Logit Plot",
    x = "Keyword Popularity",
    y = "Empirical Logit"
  ) +
  theme_minimal()
p12<- ggplot(data = newsdf, aes(x = global_subjectivity, y = log_odds)) +
  geom_point(size = 3, color = "blue") +  # Plot empirical logits
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Fit a line
  labs(
    title = "Empirical Logit Plot",
    x = "Overall Subjectivity",
    y = "Empirical Logit"
  ) +
  theme_minimal()
p13<- ggplot(data = newsdf, aes(x = title_sentiment_polarity, y = log_odds)) +
  geom_point(size = 3, color = "blue") +  # Plot empirical logits
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Fit a line
  labs(
    title = "Empirical Logit Plot",
    x = "Title's Sentiment Polarity",
    y = "Empirical Logit"
  ) +
  theme_minimal()

grid.arrange(p11, p12, p13, ncol = 3)
```

The empirical logit plots offer further insight into the relationship between key predictors and the binary outcome is_viral. The plot for average shares of average keywords reveals a positive relationship with virality. As the average popularity of an article's keywords increases, the likelihood of the article going viral rises sharply, with the empirical logit showing an upward linear trend. This suggest that keyword selection plays a key role in driving article engagement and affirms kw_avg_avg is a key predictors in modeling vitality. In contrast, the plot of overall subjectivity indicated on a slight positive relationship. Although the fitted line trends upward, the data are widely dispersed, and the effect appears weak and inconsistent, implying subjectivity alone is not a reliable driver of viral outcomes. A similar conclusion can be drawn from the plot of title sentiment polarity. While there is a marginal positive slope, suggesting that more positive titles generate a slightly greater chance of going viral, the overall relationship is weak. The plots highlight a clear distinction in predictive power among the variables and support prioritizing keyword metrics over emotional tone or subjectivity when modeling article vitality.

### Methodology

Since initial EDA revealed a heavy right skew in the distribution of article shares, as well as a poential non-linear relationship, we elected to use a logistic regression model with a transformed binary response variable.

\[INCLUDE ATTEMPT AT LINEAR referencing appendix\]

Based on our initial EDA and empirical logit visualization, we selected data channel, day published, article subjectivity, title sentiment polarity, log transformed 'avg keyword popularity', and log transformed article content length to fit an initial logistic model.

For the response variable, we constructed "is_viral" by transforming 'share' count into a binary response variable, with 1 for articles more popular than 1400 shares and 0 for those with less. We selected this threshold of 1400 shares based on prior literature\[CITE HERE\] and the recommendation of the data set curator. \## Model Specification

$$ 
\begin{aligned}
\text{logit}(P(\text{is\_viral} = 1)) &= \beta_0 \\
&+ \beta_1 \times \log(\text{kw\_avg\_avg} + 0.0001) \\
&+ \beta_2 \times \log(\text{n\_tokens\_content} + 0.0001) \\
&+ \beta_3 \times \text{data\_channel} \\
&+ \beta_4 \times \text{day\_published} \\
&+ \beta_5 \times \text{global\_subjectivity} \\
&+ \beta_6 \times \text{title\_sentiment\_polarity}
\end{aligned}
$$

\[can explain output/visualizations for log transform in appendix\]

```{r}
#| label: log-model 

newsdf$is_viral <- ifelse(newsdf$shares >= 1400, 1, 0)


logistic_model <- glm(is_viral ~ log(kw_avg_avg + 0.0001)  + log(n_tokens_content + 0.0001) + data_channel +
                  day_published + global_subjectivity +
                  title_sentiment_polarity, 
                family = binomial(link = "logit"),
                data = newsdf)

tidy(logistic_model) |>
  mutate(
    estimate = round(estimate, 4),
    std.error = round(std.error, 4),
    statistic = round(statistic, 4),
    p.value = round(p.value, 4)
  ) %>%
  kable(digits = 4, align = "lrrrr",
        col.names = c("Term", "Estimate", "Std.Error", "z-statistic", "p-value"))
```

Our initial fit gives all of the predictors significant p-values (p\<0.05) and most predictors relatively high magnitude z-statistics, indicating that all variables in the model have statistically significant relationships with the likelihood of content going viral.

## Coefficent Analysis

When fitting our model, we also visualized the adjusted odds ratios to ensure that all predictors were statistically significant.

```{r}
#| label: coefficient-estimates 

model_odds_ratios <- tidy(logistic_model, exponentiate = TRUE, conf.int = TRUE)

ggplot(data = model_odds_ratios, aes(x = term, y = estimate)) +
  geom_point() +
  geom_hline(yintercept = 1, lty = 2) + 
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high))+
  labs(title = "Adjusted odds ratios",
       x = "",
       y = "Estimated AOR") +
  coord_flip()
```

From this initial visualization, none of the 95% confidence intervals for our predictor coefficients included 1, suggesting that they were all statistically significant. While we had a couple predictors whose confidence intervals were close to 1, we decided to still keep them in the model as day_published_Thursday is one of the factors of the day_published variable, and thus it's acceptable that some of the levels for day_published were not necessarily significant because the other levels were. To add, we decided to keep log(n_tokens_content) as we both saw a possible interaction effect in the earlier EDA and we felt that it was at least a valuable predictor to consider in our model.

## Interaction Effects

Next, we considered the addition of poetential interaction effects between article length and data channel, and between global subjectivity and data channel. The hypothesis for this experiment were:

$$
H_o : B_{n-tokens-content *data-channel } =0 \\ H_A: B_{n-tokens-content *data-channel } \neq0 
$$

```{r}
#| echo: false
#| message: false
#| warning: false

nullMod <- glm(is_viral ~ log(kw_avg_avg+0.0001) + log(n_tokens_content+0.0001) + data_channel +
                 day_published + global_subjectivity +
                 title_sentiment_polarity, 
               family = binomial(link = "logit"),
               data = newsdf)

interactsMod <- glm(is_viral ~ log(kw_avg_avg+0.0001) + log(n_tokens_content+0.0001) + data_channel +
                     day_published + global_subjectivity +
                     title_sentiment_polarity + log(n_tokens_content+0.0001) * data_channel + 
                      global_subjectivity * data_channel, 
                   family = binomial(link = "logit"),
                   data = newsdf)

# Extract log-likelihoods
L_0 <- glance(nullMod)$logLik
L_a <- glance(interactsMod)$logLik

# Calculate test statistic
G <- -2 * (L_0 - L_a)

# Calculate p-value
p_value <- pchisq(G, df = 5, lower.tail = FALSE)

# Create table for drop in deviance test
deviance_table <- tibble(
  Model = c("Null Model", "Interaction Model"),
  `Log-Likelihood` = c(L_0, L_a),
  `Deviance Statistic (G)` = c(NA, G),
  df = c(NA, 5),
  `p-value` = c(NA, p_value)
)

# Display table using knitr::kable
knitr::kable(deviance_table, 
             caption = "Drop in Deviance Test Results",
             digits = c(0, 3, 3, 0, 4))

```

Examining the output of the deviance test, the p-value is very low, at around 0. This indicates that the data provides sufficient evidence that at-least one of the newly added interaction terms is a statistically significant predictor in whether an article will go viral or not, after accounting for data channel, day published, global subjectivity, title sentiment polarity, average key word popularity, and main body length for a given article. Therefore, we will keep the interaction effects in the final model.

## Model Evaluation and Comparison

```{r}
#| label: model-evaluation
#| fig.width: 10
#| fig.height: 5

# Function to prepare ROC data
prepare_roc_data <- function(model, data, model_name) {
  # Generate predicted probabilities
  probs <- predict(model, type = "response")
  
  # Augment model with predictions
  aug_data <- augment(model) |>
    mutate(
      is_viral = as.factor(.data$is_viral),
      probability = probs,
      model = model_name
    )
  
  return(aug_data)
}

# Prepare data for both models
aug_null <- prepare_roc_data(nullMod, newsdf, "Initial Model")
aug_interact <- prepare_roc_data(interactsMod, newsdf, "Interaction Model")

# Combine data for comparison
combined_aug <- bind_rows(aug_null, aug_interact)

# Generate ROC curves
roc_data <- combined_aug |>
  group_by(model) |>
  roc_curve(is_viral, probability, event_level = "second")

# Calculate AUC values
# Calculate AUC for each model separately to avoid group_by issues
auc_null <- roc_auc(
  data = filter(combined_aug, model == "Initial Model"),
  truth = is_viral,
  probability,
  event_level = "second"
)

auc_interact <- roc_auc(
  data = filter(combined_aug, model == "Interaction Model"),
  truth = is_viral,
  probability,
  event_level = "second"
)

# Combine AUC values
auc_values <- bind_rows(
  mutate(auc_null, model = "Initial Model"),
  mutate(auc_interact, model = "Interaction Model")
)

# Create separate ROC curve plots and arrange them in a grid
# Generate ROC data for each model separately
roc_data_null <- aug_null |>
  roc_curve(is_viral, probability, event_level = "second")

roc_data_interact <- aug_interact |>
  roc_curve(is_viral, probability, event_level = "second")

# Plot for Initial Model
plot_null <- ggplot(roc_data_null, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.2, color = "#E41A1C") +
  geom_abline(lty = 2, alpha = 0.5, slope = 1, intercept = 0) +
  coord_equal() +
  labs(
    title = "Initial Model",
    subtitle = paste("AUC =", round(filter(auc_values, model == "Initial Model")$.estimate, 4)),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)"
  ) +
  theme_minimal()

# Plot for Interaction Model
plot_interact <- ggplot(roc_data_interact, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.2, color = "#4DAF4A") +
  geom_abline(lty = 2, alpha = 0.5, slope = 1, intercept = 0) +
  coord_equal() +
  labs(
    title = "Interaction Model",
    subtitle = paste("AUC =", round(filter(auc_values, model == "Interaction Model")$.estimate, 4)),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)"
  ) +
  theme_minimal()

# Arrange plots side by side using gridExtra
library(gridExtra)
grid.arrange(plot_null, plot_interact, 
             ncol = 2,
             top = "ROC Curves Comparison")

# Display AUC values
kable(auc_values, 
      caption = "AUC Values for Both Models",
      digits = 4)
```

From the ROC curves, we can see that 1) Both models have an ROC curve above the random threshold, approaching the top left corner, indicating some predictive power in classifying an article 2) The Interaction Model (AUC = 0.6902) demonstrates marginally better predictive performance than the Initial Model (AUC = 0.681), confirming our belief that the interaction effects are meaningful predictors. 3) Based on the curve, the optimal threshold for our model should target sensitivity \~ 0.65.

Selecting the point closest to the ROC curve to sensitivity 0.65 yields a threshold of approximately 0.464.

```{r}
#| label: threshold-selection

target_sensitivity <- 0.65

#interation model only
roc_data_int <- aug_interact |>
  roc_curve(is_viral, probability, event_level = "second")

closest_point <- roc_data_int |>
  mutate(diff = abs(sensitivity - target_sensitivity)) |>
  arrange(diff) |> 
  slice(1)

# Display selected threshold
optimal_threshold <- closest_point$.threshold
cat("Optimal threshold for classification:", round(optimal_threshold, 3))
```

Model Performance

```{r}
#| label: roc-curve-interaction 
#| echo: false

# Generate predicted probabilities for ROC analysis
prob_roc_int <- predict(interactsMod, type = "response")
# Augment model and add probabilities
aug_data_int <- augment(interactsMod) |>
  mutate(
    is_viral = as.factor(is_viral),
    prob_roc_int = prob_roc_int
  )
# Generate ROC data
roc_data_int <- aug_data_int |>
  roc_curve(is_viral, prob_roc_int, event_level = "second")
# Plot ROC curve
autoplot(roc_data_int)

# Calculate AUC
auc_result_int <- roc_auc(
  data = aug_data_int,
  truth = is_viral,
  prob_roc_int,
  event_level = "second"
)
```

```{r}
#| label: select-threshold-interaction 

target_sensitivity <- 0.65

closest_point <- roc_data_int |>
  mutate(diff = abs(sensitivity - target_sensitivity)) |>
  arrange(diff) |> 
  slice(1)

closest_point$.threshold
```

```{r}
#| echo: false
#| fig.cap: "Confusion Matrix for the Interaction Model"

# Predict log-odds using the interaction model
log_odds_int <- predict(interactsMod, newdata = newsdf)
news_eval <- newsdf |>
  bind_cols(log_odds_int = log_odds_int)
# Convert to predicted probabilities
news_eval <- news_eval |>
  mutate(
    prob_int = exp(log_odds_int) / (1 + exp(log_odds_int))
  )
news_eval <- news_eval |>
  mutate(
    predicted_label = case_when(
      prob_int < 0.482 ~ 0,
      prob_int >= 0.482 ~ 1,
      TRUE ~ NA_real_
    ),
    predicted_label = as.factor(predicted_label),
    is_viral = as.factor(is_viral)
  )
conf_matrix_int <- news_eval |>
  conf_mat(is_viral, predicted_label)
autoplot(conf_matrix_int, type = "heatmap")
```

```{r}
auc_result_int <- roc_auc(
  data = aug_data_int,
  truth = is_viral,
  prob_roc_int,
  event_level = "second"
)
auc_result_int
```

### Results

The final model we fitted was:

$$
\begin{aligned}
\text{logit}(p_{isViral}) &= -1.3623 \\& +\ 0.0004 \times \text{kwAvgAvg} \\& +\ 0.0003 \times \text{nTokensContent} \\& -\ 0.6580 \times \text{dataChannelEntertainment} \\& +\ 0.8882 \times \text{dataChannelSocialMedia} \\& +\ 0.4839 \times \text{dataChannelTechnology} \\& -\ 0.5048 \times \text{dataChannelWorld} \\& -\ 0.1092 \times \text{dayPublishedTuesday} \\& -\ 0.1194 \times \text{dayPublishedWednesday} \\& +\ 0.1450 \times \text{dayPublishedFriday} \\& +\ 1.0247 \times \text{dayPublishedSaturday} \\& +\ 0.8979 \times \text{dayPublishedSunday} \\& +\ 0.5384 \times \text{globalSubjectivity} \\& +\ 0.2244 \times \text{titleSentimentPolarity}
\end{aligned}
$$

```{r}
#| label: interact-mod-coeff

tidy(interactsMod) |>
  kable(digits = 3)
```

```{r}
#| label: model-info 

TN <- 9673
FP <- 5805
FN <- 5574
TP <- 10359

accuracy <- (TP + TN) / (TP + TN + FP + FN)
misclassification <- (FP + FN) / (TP + TN + FP + FN)
sensitivity <- TP / (TP + FN)  # Recall
specificity <- TN / (TN + FP)
precision <- TP / (TP + FP)
FPR <- FP / (FP + TN)
FNR <- FN / (FN + TP)


metrics_table <- data.frame(
  Metric = c("Accuracy", "Misclassification Rate", "Sensitivity (Recall)", "Specificity", 
             "Precision", "False Positive Rate (FPR)", "False Negative Rate (FNR)", "AUC"),
  Value = c(accuracy, misclassification, sensitivity, specificity, 
            precision, FPR, FNR, auc_result_int$.estimate)
)

kable(metrics_table, digits = 3, caption = "Logistic Model Metrics Summary")
```

```{r}
vif_results <- vif(logistic_model)
print(vif_results)  
```

Our logistic regression model has an AUC of around 0.687, an accuracy of 0.638, specificity of 0.625, and sensitivity of 0.650. In comparison, the misclassification rate, FPR, and FNR were 0.362, 0.375, and 0.350, respectively. This suggests that our model is moderately well-fit for the data. While the accuracy, specificity, sensitivity, and precision were relatively high at around 0.640, the FNR, FPR, and misclassification rates were lower at around 0.360. This precision means that approximately 64% of articles predicted to be viral were correctly classified, indicating that the model performs substantially better than random chance. The relatively low predictive power may also be due to random noise, as many features influencing article virality are likely uncaptured by the dataset, and virality itself may be shaped by sudden trends.

From our model, we can conclude that several key factors significantly influence article virality:

Data Channel category plays a critical role. Notably, the odds of articles in the Social Media and Technology categories to go viral are approximately 15.66 times and 4.76 times that of a similar article in the Business category (reference group). Similarly, Entertainment and World news articles also show significantly higher odds of going viral than similar Business news articles, with odds ratios of 2.44 and 2.20, respectively. This suggests that readers are particularly engaged with content about social media and technology innovations, and also tend to share Entertainment and World news more than articles about Business news, however, not to the degree of Social Media and Technology articles. 

Day of publication is another important factor. Weekend publications significantly outperform weekday content. Compared to Monday, Saturday articles have 2.81 times the odds , and Sunday articles have 2.47 times the odds of going viral, holding all else constant. In contrast, the odds of Tuesday and Wednesday articles going viral are 11.7% and 13.5% lower, with odds ratios of 0.883 and 0.865, respectively, than similar Monday articles. This weekend effect likely arises from increased leisure time, as people take off from work or school during the weekend.

Article subjectivity and sentiment also significantly impact virality. A fully subjective article (global subjectivity = 1) has 6.12 times the odds of going viral compared to a fully objective article (global subjectivity = 0), keeping all else constant. Similarly, a one-unit increase in title sentiment polarity (a neutral article compared to strongly positive) increases the odds of virality by 26.6%. This trend supports the idea that emotionally charged or opinionated content tends to be shared more frequently than neutral content. 

Keyword popularity also plays a role in determining the odds of an article going viral. Specifically, every time keyword popularity is doubled, the odds of an article going viral increase by about 29.1%, holding all else constant. While article length is a statistically significant predictor of an article’s virality, its impact is minimal. Specifically, every 10% increase in article length increases the odds of virality by approximately 1.55%, holding all else constant. Thus, while article length still adds to our model, it doesn’t add as much as predictors like day published or data channel.  

Through our empirical logit graphs, visualizations, and drop in deviance test we also found statistically significant interaction effects for both article length and global subjectivity with data channel category. 

For Entertainment and World news, the benefit of article length is diminished or even reversed.  For Entertainment articles, every 10% increase in article length leads to a 1.9% decrease in the odds of going viral compared to a similar Business article, while for World news, a 10% increase in article length results in a 2.5% decrease in odds. The interaction terms between article length and Social Media or Technology is not statistically significant, suggesting the main effect of article length dominates in those categories.

In Social Media articles, a fully subjective tone actually reduces the odds of virality by 98.3%, despite the strong main effect of subjectivity. This suggests that objective tone may be more prone to virality for Social Media. In comparison, for Technology articles, subjectivity decreases odds by 82.6%. However, for both Entertainment and World news, these interaction effects are not statistically significant, which suggests that subjectivity could still hold a positive or neutral effect. 

### **Appendix**

```{r}
#| label: confusion-matrix

log_odds_2 <- predict(logistic_model, newsdf)
newsdf <- newsdf |>
  bind_cols(log_odds_2 = log_odds_2)
newsdf <- newsdf |>
  mutate(
    predict_prob = exp(log_odds_2) / (1 + exp(log_odds_2))
  )

newsdf <- newsdf |>
  mutate(
    estimateVirality = case_when(
      predict_prob < 0.4916522 ~ 0,
      predict_prob > 0.4916522 ~ 1,
      TRUE ~ NA_real_  
    )
  )

newsdf <- newsdf |> 
  mutate(
         estimateVirality = as.factor(estimateVirality),
         is_viral = as.factor(is_viral)
         )

model_conf <- newsdf |>
  conf_mat(is_viral,estimateVirality)

autoplot(model_conf, type="heatmap")

```

**Exploratory Data Analysis:**

**Data Set Description**: 

Our project utilizes the University of California Irvine Machine Learning Repository’s  “Online News Popularity” data set. It includes share counts and descriptive characteristics for articles published by Mashable over two years (from 2013 to 2015). Mashable Inc. is a digital media website founded in 2005 and as of November 2015, it has over 6,000,000 Twitter followers and over 3,200,000 fans on Facebook. The data set in total, has 39644 observations, each representing an individual article. Observations include characteristics such as: Number of Words in Title/Content, Rate of Unique Words, Number of Images, Data Channel, Day Published, Rate of Positive/Negative Words, Polarity, etc.  Our intention is to use the data set to predict the number of shares/virality of an article based on different variables. 

**Key Variables**: 

rate_positive_words -  rate of positive words among non-neutral tokens, which captures how emotionally charged the language is. 

Rate_negative_words - rate of negative words among non-neutral tokens, which captures how emotionally charged the language is. 

title_sentiment_polarity - A measure of how polarizing the title is

N_tokens_content - A measure of how long the article’s content is 

N_tokens_title -  A measure of how long the article title is

data_channel - a categorical variable denoting article topic merged from: Data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, and data_channel_is_world.

day_published- a categorical variable indicating publication day merged from indicators: Weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday,weekday_is_saturday, weekday_is_sunday 

\break

[Data Cleaning]{.underline}

First we have to combine the existing weekday and data_channel indicator variables into their respective categorical variables.

```{r}
newsdf$day_published <- NA  # Create a new empty column

newsdf$day_published <- case_when(
  newsdf$weekday_is_monday == 1 ~ "Monday",
  newsdf$weekday_is_tuesday == 1 ~ "Tuesday",
  newsdf$weekday_is_wednesday == 1 ~ "Wednesday",
  newsdf$weekday_is_thursday == 1 ~ "Thursday",
  newsdf$weekday_is_friday == 1 ~ "Friday",
  newsdf$weekday_is_saturday == 1 ~ "Saturday",
  newsdf$weekday_is_sunday == 1 ~ "Sunday",
)

newsdf$day_published <- factor(
  newsdf$day_published,
  levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
)


newsdf$data_channel <- NA

newsdf$data_channel <- case_when(
  newsdf$data_channel_is_entertainment == 1 ~ "Entertainment",
  newsdf$data_channel_is_bus == 1 ~ "Business",
  newsdf$data_channel_is_socmed == 1 ~ "Social Media",
  newsdf$data_channel_is_tech == 1 ~ "Technology",
  newsdf$data_channel_is_world == 1 ~ "World",
)

newsdf$data_channel <- factor(newsdf$data_channel)


tab <- newsdf %>%
  select(url, day_published, data_channel) %>%
  head(5)
kable(tab, caption = "Transformed Data")
  
```

```{r}
ggplot(data =newsdf, aes(x=data_channel))+
  geom_bar(fill = "green")+
  labs(
    x ="Data Channel",
    y= "Relative Frequency", 
    title = "Distribution of article catagories"
  )
```

Next, we discovered that approx 8,233 articles are not tagged for a specific data channel. Due to the nature of the dataset, it's unclear if this was because the article was simply missing a tag, it was mis-tagged while being collected, or if it simply doesn't belong in any of these categories. With the relatively large size of our dataset, we decided to exclude entries lacking a data tag NA's from our data channel analysis altogether. These articles lacking a data channel were filtered out.

```{r}
newsdf<- newsdf |> 
  filter(!is.na(data_channel))
```

[Response Variable/Univariate EDA]{.underline}

```{r}
#| label: initial-explore

ggplot(newsdf, aes(x = shares)) +
  geom_histogram(binwidth = 500, fill = "blue", color = "black", alpha = 0.7) +
  scale_x_continuous(limits = c(0, 50000)) +  # Limit for better visualization
  labs(title = "Distribution of Article Shares",
       x = "Number of Shares",
       y = "Count") +
  theme_minimal()
```

```{r}
newsdf |>
  summarize(
    mean_shares = mean(shares),
    median_shares = median(shares),
    sd_shares = sd(shares),
    min_shares = min(shares),
    max_shares = max(shares),
    q1 = quantile(shares, 0.25),
    q3 = quantile(shares, 0.75)
  )
```

The distribution of \# of shares is highly right skewed, a median of 1400 shares and a few highly shared articles. Notably, the mean of 2878 shares is far larger

```{r}
#| label: zoom-in-response

ggplot(newsdf, aes(x = shares)) +
  geom_histogram(binwidth = 500, fill = "blue", color = "black", alpha = 0.7) +
  scale_x_continuous(limits = c(0, 10000)) +  # Zoom in on the first 10,000 shares
  labs(title = "Distribution of Article Shares (Zoomed In)",
       x = "Number of Shares",
       y = "Count") +
  theme_minimal()

```

To make deal with this strong right skew, we applied a log transformation to the share variable, yielding a less skewed distribution.

```{r}
#| label: log-transform

ggplot(newsdf, aes(x = log(shares))) +  
  geom_histogram(binwidth = 0.2, fill = "purple", color = "black", alpha = 0.7) +
  labs(title = "Log-Transformed Distribution of Shares",
       x = "Log(Shares)",
       y = "Count") +
  theme_minimal()
```

[Predictor Variable/Univariate EDA]{.underline}

```{r}
themeA <- theme_minimal() +
  theme(axis.title.y = element_blank())  

a1 <- ggplot(newsdf, aes(x = rate_positive_words)) +
  geom_histogram(binwidth = 0.02, fill = "green", color = "black") +
  labs(title = "Positive Words Rate",
       x = "Rate of positive words") + 
  themeA

a2 <- ggplot(newsdf, aes(x = rate_negative_words)) +
  geom_histogram(binwidth = 0.02, fill = "red", color = "black") +
  labs(title = "Negative Words Rate",
       x = "Rate of negative words") + 
  themeA

a3 <- ggplot(newsdf, aes(x = title_sentiment_polarity)) +
  geom_histogram(binwidth = 0.02, fill = "blue", color = "black") +
  labs(title = "Title Polarity",
       x = "Polarity score") + 
  themeA

a4 <- ggplot(newsdf, aes(x = n_tokens_content)) +
  geom_histogram(binwidth = 100, fill = "purple", color = "black") +
  labs(title = "Article Length",
       x = "Number of words") + 
  themeA

a5 <- ggplot(newsdf, aes(x = n_tokens_title)) +
  geom_histogram(binwidth = 1, fill = "pink", color = "black") +
  labs(title = "Title Length",
       x = "Number of words") + 
  themeA

grid.arrange(a1, a2, a3, a4, a5, ncol = 3, 
             left = "Frequency", 
             top = "Distribution of Article Features")
```

Examining the rate of positive words in an article, we see a left skew distribution, with modes at \~0, \~0.75 and \~1. The median positivity is approx 0.71 positivity rate, and the range is from 0 to 1.

```{r}
ggplot(newsdf, aes(x = rate_positive_words)) +
  geom_histogram(binwidth = 0.02, fill = "green", color = "black") +
  labs(title = "Rel. Freq of Positive Words Rate",
       x = "Rate of positive words",
       y= "Frequency")
```

```{r}
newsdf |>
  summarize(
    mean= mean(rate_positive_words),
    median = median(rate_positive_words),
    std.dev = sd(rate_positive_words),
    min = min(rate_positive_words),
    max = max(rate_positive_words),
  )
```

The rate of negative words shows the opposite trend, with a slight right skew. Similarly, there seems to be a second mode at 0 negativity. The median is approx 0.28 negativity rate, with an approximately equal mean.

```{r}
ggplot(newsdf, aes(x = rate_negative_words)) +
  geom_histogram(binwidth = 0.02, fill = "red", color = "black") +
  labs(title = "Rel Freq of Negative Words Rate",
       x = "Rate of negative words",
       y= "Frequency")
```

```{r}
newsdf |>
  summarize(
    mean= mean(rate_negative_words),
    median = median(rate_negative_words),
    std.dev = sd(rate_negative_words),
    min = min(rate_negative_words),
    max = max(rate_negative_words),
  )
```

```{r}
ggplot(newsdf, aes(x = n_tokens_content)) +
  geom_histogram(binwidth = 100, fill = "purple", color = "black") +
  labs(title = "Rel. Freq. of Article Length",
       x = "Number of words",
       y= "frequency")

```

```{r}
newsdf |>
  summarize(
    mean= mean(n_tokens_content),
    median = median(n_tokens_content),
    std.dev = sd(n_tokens_content),
    min = min(n_tokens_content),
    max = max(n_tokens_content),
  )
```

For article length, the graph shows a strongly right-skewed distribution, with a median length of 444 and a high standard deviation of 477 words. To remedy this, we might consider a log transformation which yields a more even distribution.

```{r}
ggplot(newsdf, aes(x = log(n_tokens_content))) +
  geom_histogram( fill = "purple", color = "black") +
  labs(title = "Rel. Freq of Log transformed Article Length",
       x = "log of # of words",
       y= "frequency")
```

For the number of tokens in the title, we can see a highly symetric distribution centered at 10, with a standard deviation of 2.14.

```{r}
ggplot(newsdf, aes(x = n_tokens_title)) +
  geom_histogram(binwidth = 1, fill = "pink", color = "black") +
  labs(title = "Rel. Freq. of Title Length",
       x = "Number of words",
       y= "frequency")
```

```{r}
newsdf |>
  summarize(
    mean= mean(n_tokens_title),
    median = median(n_tokens_title),
    std.dev = sd(n_tokens_title),
    min = min(n_tokens_title),
    max = max(n_tokens_title),
  )
```

Finally, our initial EDA of title polarity found a massive frequency spike at 0 frequency, which might correspond to failed measurements or the vast majority of our articles not presenting signifigant title polarity.

```{r}
ggplot(newsdf, aes(x = title_sentiment_polarity)) +
  geom_histogram(binwidth = 0.02, fill = "blue", color = "black") +
  labs(title = "Title Polarity",
       x = "Polarity score",
       y= "Frequency") 
```

To fix this issue and for ease of use, we catagorized articles into negative, neutral and positive polarity, with a threshold of 0 +- 0.05 for neutral. Most titles remain neutral, and there are more positive than negative headlines.

```{r}
newsdf$title_sentiment_category <- cut(newsdf$title_sentiment_polarity,
                                       breaks = c(-Inf, -0.05, 0.05, Inf),
                                       labels = c("Negative", "Neutral", "Positive"))
ggplot(newsdf, aes(x = title_sentiment_category, fill = title_sentiment_category)) +
  geom_bar() +
  scale_fill_manual(values = c("Negative" = "red", "Neutral" = "gray", "Positive" = "blue")) +
  labs(title = "Distribution of Title Sentiment Polarity",
       x = "Sentiment Category",
       y = "Count") +
  theme_minimal()
```

[Bi-variate EDA]{.underline}

```{r}
p1 <- ggplot(newsdf, aes(x = rate_positive_words, y = log(shares))) +
  geom_point( color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Log(Shares) vs Rate of Positive Words",
       x = "Rate of Positive Words", 
       y = "Log(Shares)") +
  theme_minimal()

p2 <- ggplot(newsdf, aes(x = rate_negative_words, y = log(shares))) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Log(Shares) vs Rate of Negative Words",
       x = "Rate of Negative Words", 
       y = "Log(Shares)")
grid.arrange(p1, p2, ncol = 2)
```

By plotting the rate of positive words and the rate of negative words against the log transformed share, we can see that neither have a particularly strong relationship with how often the article is shared. The rate of positive words seems to have a weak positive relationship with shares, and the rate of negative words seems to have a weak negative relationship, but both have significant outliers are 1 and 0.

```{r}
ggplot(newsdf, aes(x = title_sentiment_category, y = (shares), fill = title_sentiment_category)) +
  stat_summary(fun = "mean", geom = "bar") +
  scale_fill_manual(values = c("Negative" = "red", "Neutral" = "gray", "Positive" = "blue")) +
  labs(title = "Average Shares by Title Polarity",
       x = "Title Polarity Category",
       y = "Average Shares") +
  theme(legend.position = "none")
```

In contrast, there seems to be some relationship between title polarity and the number of shares, with positive polarity associated with greater share counts.

Next,

```{r}
f1<- ggplot(newsdf, aes(x = (n_tokens_content), y = log(shares))) +
  geom_point( color = "violet") +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Log(Shares) vs Article Length",
       x = "Article Length(Words)", 
       y = "Log(Shares)") +
  theme_minimal()

f2<- ggplot(newsdf, aes(x = log(n_tokens_content), y = log(shares))) +
  geom_point( color = "violet") +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Log(Shares) vs Article Length",
       x = "log(Article Length(Words))", 
       y = "Log(Shares)") +
  theme_minimal()

grid.arrange(f1,f2,ncol=2)
```

These graphs show a weak, positive relationship between article length and the log transformed number of shares. Due to the skew, we can apply the log transform to the article length. This shows a more even distribution, with no clear relationship.

Similarly, there doesn't seem to be any clear relationship between title length and the number of shares in the graph below.

```{r}
 ggplot(newsdf, aes(x = (n_tokens_title), y = log(shares))) +
  geom_point( color = "gold") +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Log(Shares) vs Title Length",
       x = "Title Length(Words)", 
       y = "Log(Shares)") +
  theme_minimal()


```

```{r}
#| label: distribution-day 

news_summary <- newsdf |>
  group_by(day_published) |> 
  summarize(mean_shares = mean(shares)) 

head(news_summary)
news_summary|>
  ggplot(aes(x = day_published, y = mean_shares)) +
  geom_bar(stat = "identity", fill = "skyblue") + 
  labs(
    x = "Day Published", 
    y = "Mean Number of Article Shares",
    title = "Mean Number of Article Shares vs. Day Published"
  )

```

```{r}
model <- lm(log(shares) ~ rate_negative_words + rate_positive_words, data =newsdf ) 
  tidy(model)|>
  kable(digits=3)

```

```{r}
vif_values <- vif(model)
print("Variance Inflation Factors:")
print(vif_values)
```

This visualization and summarization suggests that the day an article is published does not have a significant impact on the virality of an article, as the mean number of article shares do not differ much between days. Therefore, this predictor may not be as important as others when it comes to predicting the virality of an article.

```{r}
#| label: data-channel-vis 

news_summary_channel <- newsdf |>
  group_by(data_channel) |> 
  summarize(mean_shares = mean(shares)) 

head(news_summary_channel)
news_summary_channel |>
  drop_na(data_channel) |>
  ggplot(aes(x = data_channel, y = mean_shares)) +
  geom_bar(stat = "identity", fill = "skyblue") + 
  labs(
    x = "Data Channel", 
    y = "Mean Number of Article Shares",
    title = "Mean Number of Article Shares vs. Data Channel"
  )
```

From our visualizations, it appears that articles that are in the social media data channel perform the best in terms of average number of shares (\~3600), while articles that are in the World data channel perform the worst (\~2250). Business, Entertainment, and Technology articles all seem to receive a mean of about 3000 shares. However, from our earlier univariate analysis, we saw that the Social Media Data Channel has the lowest number of articles, and thus there is a possibility that any outliers for this data channel category would have a larger impact in skewing the mean.

[Interaction Effects Exploration]{.underline}

```{r}
#| label: model-interact

# Base model without interaction
model1 <- lm(log(shares) ~ n_tokens_content + n_tokens_title, data = newsdf)

# Model with interaction effect
model2 <- lm(log(shares) ~ n_tokens_content + n_tokens_title +
         	n_tokens_content:n_tokens_title, data = newsdf)

# Create tidy dataframes of results with model labels
summary_model1 <- tidy(model1) %>% mutate(Model = "Model 1")
summary_model2 <- tidy(model2) %>% mutate(Model = "Model 2")

# Display combined coefficient table
kable(rbind(summary_model1, summary_model2),
  	digits = 3,
  	col.names = c("Term", "Estimate", "Std. Error", "t value", "p-value", "Model"),
  	caption = "Regression Coefficients for Both Models")

# Compare models using ANOVA
model_comparison <- tidy(anova(model1, model2))
kable(model_comparison, digits = 3, caption = "ANOVA Comparison of Models")

```

When comparing linear models with the title and article length as predictors, we explored to see if an interaction effect would have a meaningful difference. Our results show that the effect of title length depends on article length. IE, for very short articles, we'd expect longer titles to be beneficial and for longer articles, vice versa.

```{r}
#| label: interact-channel
news_summary <- newsdf |>
  drop_na(data_channel) |>
  group_by(data_channel, title_sentiment_category) |>
  summarize(mean_shares = mean(shares, na.rm = TRUE))

news_summary |>
  ggplot(aes(x = title_sentiment_category, y = mean_shares)) + 
  geom_bar(stat = "identity", fill = "skyblue") + 
  facet_wrap(~ data_channel) +
  labs(
    title = "Mean Shares for Title Sentiment Categories",
    subtitle = "Faceted by Data Channel Type",
    x = "Title Sentiment"
  )
```

From this visualization, it's suggested that the title sentiment may have different impacts on the mean number of shares depending on the type of data channel, thus suggesting that there may be a statistically significant interaction effect between the title sentiment and the data channel type. For instance, while for Social Media and Entertainment, it appears that articles with a Negative sentiment have the greatest number of mean shares, for World and Technology articles, Positive sentiment articles had the greatest mean shares, and for Business, Neutral sentiment articles had the greatest number.

```{r}
#| label: news-fit

news_fit <- lm(log(shares) ~ data_channel + title_sentiment_category + data_channel * title_sentiment_category, data = newsdf)

tidy(news_fit) |>
  kable(digits = 3)
```

However, when looking at the actual fitted model, all the interaction terms between the data channel and the sentiment category have large p-values (greater than 0.05) suggesting that none of the interaction terms are actually statistically significant between data channel and title sentiment category. In the future we could consider looking at the mean of the shares rather than the log, as it appears as though there may be interaction effects for the mean but not the log of the shares.

```{r}
#| label: more-interaction

title_fit_mod <- lm(log(shares) ~ n_tokens_title + data_channel * n_tokens_title + data_channel, data = newsdf) 
tidy(title_fit_mod) |>
  kable(digits = 3)
```

From this model, we found that while the data channel type at times has a statistically significant linear relationship to log(shares), specifically for Social Media, Technology, and World, the number of words in the title does not have a linear relationship to log(shares), based on their respective p-values. For instance, the p-value for n_tokens_title is 0.677, thus suggesting that there is not a statistically significant linear relationship between n_tokens_title and log(shares). However, while the number of words in the title does not have a significant linear relationship with log(shares) directly, its interaction term specifically with when the data channel is World, is significant (as shown by the p-value of 0.003).

```{r}
#| label: distribution-day-pub

news_summary <- newsdf |>
  group_by(day_published) |> 
  summarize(mean_shares = mean(shares)) 

head(news_summary)
news_summary|>
  ggplot(aes(x = day_published, y = mean_shares)) +
  geom_bar(stat = "identity", fill = "skyblue") + 
  labs(
    title = "Mean Article Shares by Day of Publication", 
    subtitle = "Weekend articles tend to receive more shares",
    x = "Day Published", 
    y = "Mean Number of Shares",
  )
```

```{r}
#| label: data-channel-explore

news_summary_channel <- newsdf |>
  group_by(data_channel) |> 
  summarize(mean_shares = mean(shares)) 

head(news_summary_channel)
news_summary_channel |>
  drop_na(data_channel) |>
  ggplot(aes(x = data_channel, y = mean_shares)) +
  geom_bar(stat = "identity", fill = "skyblue") + 
  labs(
    title = "Mean Article Shares by Content Category", 
    subtitle = "Social Media articles more popular than other catagories",
    x = "Content Category", 
    y = "Mean Number of Shares",
  ) 
```
